# Hand-Landmark-Based-Sign-Language-recognition-using-Deep-Learning
As human beingâ€™s communication is very crucial part of our life, it is  essential for sharing thoughts and ideas for our survival. We communicate  through speech, body gestures, reading, writing etc., however speech being  the most used among them. But unfortunately for the speaking and hearing impaired minority it is difficult or impossible to communicate through speech.  Sign language is one of the oldest forms of language used for communication  by speech impaired people. But most of the common people have no  knowledge about sign language and its interpretations. This is one of the major  problems faced by these kinds of people during their communications. Getting  an interpreter is not easy every time. To solve this issue, a model is developed using neural networks for  fingerspelling based on the various hand gestures. In this user independent  model, two classification machine learning algorithms are trained using a set of  image and hand skeleton dataset. The skeleton dataset is created using the  hand image dataset and is done to improve the accuracy of the model. By  using this model, a speech impaired person can easily communicate with a  person who has no knowledge of it, the model translating the hand gestures to  sentence in English.  The main issue with the current system is that, there are some group of  alphabets, whose sign language symbol look alike. This make the image base  classification model bit difficult to correctly classify and the accuracy of the  prediction can also be low. This issue can be solved using a hand skeleton  classifier. As in the hand skeleton image the position and structure of each  fingers can be identified more accurately than from an image. This make the  neural network model to learn better and can classify with higher accuracy.
